{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f665b2-033c-4557-b81a-b4b02f42c5a7",
   "metadata": {},
   "source": [
    "### Try to build a an agent that will work with client to compile and execute a sql order\n",
    " - bonus: build a tool to email the order details (including price) when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140068b8-8e40-41cc-92ce-f9c5ea477f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open ai authentication\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "import dbio\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95478ef-8361-4fb3-aa50-f65a55df1885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# email util\n",
    "\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from langchain.agents import tool\n",
    "\n",
    "def get_mail_server(server='smtp.gmail.com', port=587):\n",
    "    '''Allocate mail server on port'''\n",
    "    mailServer = smtplib.SMTP(server, port)\n",
    "    test = mailServer.starttls()  # start TLS\n",
    "    assert test[1].lower().find(b'ready') != -1\n",
    "    return mailServer\n",
    "\n",
    "def format_message(message, sender, receiver, subject):\n",
    "    '''\n",
    "    Format arguments into MIMEMultipart object\n",
    "    '''\n",
    "\n",
    "    # message\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = ', '.join(receiver)\n",
    "    msg['Subject'] = subject\n",
    "    msg.attach(MIMEText(message, 'html'))\n",
    "\n",
    "    return msg\n",
    "\n",
    "@tool\n",
    "def send_message(order_summary, email='user@user.com'):\n",
    "    \"\"\"Returns a tuple of status and the email to the user. \\\n",
    "    Use this for any questions requesting an email summary of \\\n",
    "    the order. Do not call this function until the user has \\\n",
    "    provided an email address. The input should the the summary \\\n",
    "    email and the email provided by the user. \\\n",
    "    The consruction of the email message should occur outside \\\n",
    "    outside this function.\"\"\"\n",
    "    \n",
    "    sender = 'OrderBotPizza.com'\n",
    "    subject = 'Your OrderBot Pizza Order'\n",
    "    verbose = True\n",
    "\n",
    "    msg = format_message(order_summary, sender, [email], subject)\n",
    "    '''\n",
    "    if verbose:\n",
    "        print(f'sending mail from {sender} to {receiver}')\n",
    "    with get_mail_server() as mailServer:\n",
    "        mailServer.sendmail(sender, receiver, msg.as_string())\n",
    "    '''\n",
    "    print(msg)\n",
    "    return msg, 'mail sent successfully'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ccc509-44e1-44fa-b86e-6244a5ba5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "send_message('hello time')\n",
    "\n",
    "#enabling gmail will require 2-factor authentication with google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632db549-b5a5-4960-bbf2-8b82171a76af",
   "metadata": {},
   "source": [
    "# Instantiate the components separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3010e9-cb3e-4a26-bbe2-e010d721ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562bff5-92c7-4421-b8ca-5df0830e6470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, verbose=True)\n",
    "\n",
    "# database\n",
    "db = SQLDatabase.from_uri(\"sqlite:///./pizza_v2.db\")\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c378b-e164-482d-9fab-1b0b284e2927",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8744195-ceea-4747-babf-108d58e1b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run('describe the pizzas table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eca68b-687a-4184-8a00-0321e26ca77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3a99f-a677-4159-ad05-ce00700ed0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f86b8f-e1b3-4183-b9bd-e8af4108f381",
   "metadata": {},
   "source": [
    "# try with general chat and sql tool\n",
    "\n",
    " - following the example [here](https://python.langchain.com/en/latest/modules/agents/agents/examples/chat_conversation_agent.html) of an agent that can call tools and chat with the usert too\n",
    " - Note there is no prompt specific setting the context for the OrderBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942eae0c-adef-4229-a9cc-f36adc3a2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3a88b9-d897-4f8c-a36b-e3479393a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4216b799-c56d-4f34-ba50-eb4ab37d1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fcff8ef-8cc2-404b-b650-d1a9e76d2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///./pizza_v2.db\")\n",
    "from langchain.chains import SQLDatabaseSequentialChain\n",
    "seq_chain = SQLDatabaseSequentialChain.from_llm(llm, db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f4055cd-fbc1-4c88-8ae5-743eb5eeab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = \"menu search\",\n",
    "        func=seq_chain.run,\n",
    "        description=\"\"\"useful for when you need to answer questions about menu items the user wants to order.\n",
    "        Search your chat history before deciding you need to use this.\"\"\"\n",
    "    ),\n",
    "        Tool(\n",
    "        name = \"send email\",\n",
    "        func=send_message,\n",
    "        description=\"\"\"Used when sending the use the summary email of the order. Call this only when the user \\\n",
    "        has finished entering their order and provided an email address.\"\"\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "092e6c55-80a2-43ce-902e-ec4c99f0bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(tools, llm, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "                               verbose=True, memory=memory)\n",
    "\n",
    "#agent_chain.agent.llm_chain.prompt = ChatPromptTemplate goes here, put details in system role if possible\n",
    "\n",
    "\"\"\"\n",
    "#\"\"\"\n",
    "# access chat memory with agent_chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a40184cd-2147-4196-bed5-a32af4cac12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input', 'chat_history', 'agent_scratchpad'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.', template_format='f-string', validate_template=True), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> menu search: useful for when you need to answer questions about menu items the user wants to order.\\n        Search your chat history before deciding you need to use this.\\n> send email: Used when sending the use the summary email of the order. Call this only when the user         has finished entering their order and provided an email address.\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string, \\\\ The action to take. Must be one of menu search, send email\\n    \"action_input\": string \\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}', template_format='f-string', validate_template=True), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.agent.llm_chain.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e656c-d044-4119-bae5-1a7eb2a26e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"hi, i am Tim and my email is t@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511ca8a-96e9-4ed2-b25b-efb2905dec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.agent.llm_chain.prompt # how inject the orderBot prompt with specific instrunctions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789fb550-6bdb-419f-b690-94f3d55cbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"what is my name and email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef0bd1-80fd-4648-a754-64ca43fe5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run('I would like to order a large pizz and bottled water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f756c-848f-4a42-ba58-cf149db55fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run('What sizes of bottled water do you have?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e995348-6e37-4534-a447-0057615e627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent_chain.run('I will take the bottled water.  What is you most popular pizza?')\n",
    "agent_chain.run('Add the large bottled water to my order.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c36bd-8036-4a17-ac07-8ea708097622",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run('Add the bottled water to my order.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0828971-66ee-4ad9-a438-186092bd9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"\"\"I would like the large pepperoni \\\n",
    "pizza. Please include both sausage and extra cheese as additional \\\n",
    "toppings.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f57f6-566a-4dee-9a29-3a663115e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"Please repeat my order to make sure it is right.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51898be-b3c9-4369-8a78-51c21a185f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"that is it. please email me my receipt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cbc078-984a-4830-b276-133cb46fdcea",
   "metadata": {},
   "source": [
    "Try again with custom bot following example here: https://python.langchain.com/en/latest/modules/agents/agents/custom_llm_agent.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de690024-b104-45ba-8f65-c672d3b29ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.chains import SQLDatabaseSequentialChain\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "#from langchain.agents import initialize_agent # alternative to AgentExecutor?\n",
    "#from langchain.agents import AgentType\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118cdf13-0c60-4d9c-b638-9c1bc0614e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, verbose=True)\n",
    "\n",
    "# memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# db\n",
    "db = SQLDatabase.from_uri(\"sqlite:///./pizza_v2.db\")\n",
    "seq_chain = SQLDatabaseSequentialChain.from_llm(llm, db, verbose=True)\n",
    "\n",
    "# tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"menu search\",\n",
    "        func=seq_chain.run,\n",
    "        description=\"useful for when you need to answer questions about menu items the user wants to order\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc535b-a973-4db1-b017-73fe8f496674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template\n",
    "\n",
    "# Set up the base template\n",
    "template_with_history = \"\"\"You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "You first greet the customer, then collects the order, \\\n",
    "and then asks if it's a pickup or delivery. \\\n",
    "You wait to collect the entire order, then summarize it and check for a final \\\n",
    "time if the customer wants to add anything else. \\\n",
    "If it's a delivery, you ask for an address. \\\n",
    "Finally you collect the payment.\\\n",
    "Make sure to clarify all options, extras and sizes to uniquely \\\n",
    "identify the item from the menu.\\\n",
    "You respond in a short, very conversational friendly style. \\\n",
    "\n",
    "You have access to the following tools: \\\n",
    "\n",
    "{tools} \\\n",
    "\n",
    "Use the following format: \\\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Previous conversation history:\n",
    "{history}\n",
    "\n",
    "New question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99faf4-4b4f-4705-9916-a0fad29b95c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b7668-4ee0-4991-9eee-a0eb243f6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_history = CustomPromptTemplate(\n",
    "    template=template_with_history,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936bc3c-c843-4794-9eaa-f00c86ce63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output parser\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "\n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c5d1a-8f54-4202-a16e-c72fc38f34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt_with_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad3c9a-f42e-466c-92a4-d13d9d98750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53307959-3c74-413a-9a5c-1466dbeb312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb253988-840b-427c-981b-4f1f8b12696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"How many pizzas do you have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b4d01f-7f0c-480c-8ff2-bb4d6e502e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
