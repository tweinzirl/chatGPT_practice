{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f665b2-033c-4557-b81a-b4b02f42c5a7",
   "metadata": {},
   "source": [
    "### Try to build a an agent that will work with client to compile and execute a sql order\n",
    " - bonus: build a tool to email the order details (including price) when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140068b8-8e40-41cc-92ce-f9c5ea477f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open ai authentication\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "import dbio\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d95478ef-8361-4fb3-aa50-f65a55df1885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# email util\n",
    "\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from langchain.agents import tool\n",
    "\n",
    "def get_mail_server(server='smtp.gmail.com', port=587):\n",
    "    '''Allocate mail server on port'''\n",
    "    mailServer = smtplib.SMTP(server, port)\n",
    "    test = mailServer.starttls()  # start TLS\n",
    "    assert test[1].lower().find(b'ready') != -1\n",
    "    return mailServer\n",
    "\n",
    "def format_message(message, sender, receiver, subject):\n",
    "    '''\n",
    "    Format arguments into MIMEMultipart object\n",
    "    '''\n",
    "\n",
    "    # message\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = ', '.join(receiver)\n",
    "    msg['Subject'] = subject\n",
    "    msg.attach(MIMEText(message, 'html'))\n",
    "\n",
    "    return msg\n",
    "\n",
    "def send_message(order_summary, email='user@user.com'):\n",
    "    \"\"\"\n",
    "    Send the order summary (from the order summary tool)\n",
    "    to the email indicated by the user\n",
    "    \"\"\"\n",
    "    \n",
    "    sender = 'OrderBotPizza.com'\n",
    "    subject = 'Your OrderBot Pizza Order'\n",
    "    verbose = True\n",
    "\n",
    "    msg = format_message(order_summary, sender, [email], subject)\n",
    "    '''\n",
    "    if verbose:\n",
    "        print(f'sending mail from {sender} to {receiver}')\n",
    "    with get_mail_server() as mailServer:\n",
    "        mailServer.sendmail(sender, receiver, msg.as_string())\n",
    "    '''\n",
    "    print(msg)\n",
    "    return msg, 'mail sent successfully'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ccc509-44e1-44fa-b86e-6244a5ba5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "send_message('hello time')\n",
    "\n",
    "#enabling gmail will require 2-factor authentication with google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632db549-b5a5-4960-bbf2-8b82171a76af",
   "metadata": {},
   "source": [
    "# Custom Agent w/ pizza menu in prompt\n",
    "\n",
    " - https://python.langchain.com/docs/modules/agents/how_to/custom_llm_agent\n",
    " - See if order can be taken, summarized accurately, and then emailed\n",
    " - Test for hallucinations, if wrong output try incorporating db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397aa1b-1326-4a68-b38b-5af54e819d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup env\n",
    "\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, LLMMathChain, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e96e0f-cdc6-4191-8e25-653b8feb3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# set up tool\n",
    "# Define which tools the agent can use to answer user queries\n",
    "tools = [\n",
    "    # Tool(\n",
    "    #    name=\"Calculator\",\n",
    "    #    func=LLMMathChain.from_llm(llm=llm, verbose=True).run,\n",
    "    #    description=\"useful for when you need to perform math operations\"\n",
    "    #),\n",
    "        Tool(\n",
    "            name = \"send email\",\n",
    "            func=send_message,\n",
    "            description=\"\"\"Used when sending the use the summary email of the order. Call this only when the user \\\n",
    "            has finished entering their order and provided an email address.\"\"\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa55820-5bc8-41fa-8b79-c01cfd63aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template\n",
    "\n",
    "# Set up the base template\n",
    "template_with_history = \"\"\"\n",
    "You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "You first greet the customer, then collects the order, \\\n",
    "and then asks if it's a pickup or delivery. \\\n",
    "You wait to collect the entire order, then summarize it and check for a final \\\n",
    "time if the customer wants to add anything else. \\\n",
    "If it's a delivery, you ask for an address. \\\n",
    "Finally you collect the payment and send an email record of the order.\\\n",
    "\n",
    "Make sure to clarify all options, extras and sizes to uniquely \\\n",
    "identify the item from the menu.\\\n",
    "\n",
    "You respond in a short, very conversational friendly style. \\\n",
    "\n",
    "The menu includes \\\n",
    "pepperoni pizza  12.95, 10.00, 7.00 \\\n",
    "cheese pizza   10.95, 9.25, 6.50 \\\n",
    "eggplant pizza   11.95, 9.75, 6.75 \\\n",
    "fries 4.50, 3.50 \\\n",
    "greek salad 7.25 \\\n",
    "Toppings: \\\n",
    "extra cheese 2.00, \\\n",
    "mushrooms 1.50 \\\n",
    "sausage 3.00 \\\n",
    "canadian bacon 3.50 \\\n",
    "AI sauce 1.50 \\\n",
    "peppers 1.00 \\\n",
    "Drinks: \\\n",
    "coke 3.00, 2.00, 1.00 \\\n",
    "sprite 3.00, 2.00, 1.00 \\\n",
    "bottled water 5.00 \\\n",
    "\n",
    "You have access to the following tools for sending the final summary email:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, may be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer (OR I CANNOT ANSWER THE QUESTION)\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to call the email summary tool only when you know the \\\n",
    "recipient's email address.\n",
    "\n",
    "Previous conversation history:\n",
    "{history}\n",
    "\n",
    "New question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "prompt_with_history = CustomPromptTemplate(\n",
    "    template=template_with_history,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6db7e7-5166-4870-8eca-bce3011e1370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output parser\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise OutputParserException(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "\n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d03c75-fd71-4d70-9819-e61c91832fc5",
   "metadata": {},
   "source": [
    "Define the stop sequence\n",
    "\n",
    "This is important because it tells the LLM when to stop generation.\n",
    "\n",
    "This depends heavily on the prompt and model you are using. Generally, you want this to be whatever token you use in the prompt to denote the start of an Observation (otherwise, the LLM may hallucinate an observation for you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894b406-c639-4d8b-aac6-166c36a53d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt_with_history)\n",
    "\n",
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afaa83-96d8-4bc8-bd30-230d9a8c7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory - how big is this buffer?\n",
    "\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory=ConversationBufferWindowMemory(k=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6f825-b6a7-46b5-bb7a-5026aa88b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use agent\n",
    "\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, memory=memory, \n",
    "                                                    verbose=True, max_iterations=3)\n",
    "\n",
    "agent_executor.run(\"Hello my name is Tim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f86b8f-e1b3-4183-b9bd-e8af4108f381",
   "metadata": {},
   "source": [
    "# try with conversational agent and sql tool\n",
    "\n",
    " - reference for agent that applies custom output parser: https://github.com/hwchase17/langchain/issues/2561\n",
    "\n",
    " - following the example [here](https://python.langchain.com/en/latest/modules/agents/agents/examples/chat_conversation_agent.html) of an agent that can call tools and chat with the usert too\n",
    " - Note there is no prompt specific setting the context for the OrderBot\n",
    "\n",
    " - Try adding llm-math as tool\n",
    "\n",
    " - QA chain from text document for plain text version of prompt\n",
    "\n",
    " - general custom llm agent is here: https://python.langchain.com/docs/modules/agents/how_to/custom_llm_agent\n",
    " - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "942eae0c-adef-4229-a9cc-f36adc3a2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain import LLMMathChain\n",
    "\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "from langchain.output_parsers.json import parse_json_markdown\n",
    "\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3a88b9-d897-4f8c-a36b-e3479393a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4216b799-c56d-4f34-ba50-eb4ab37d1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fcff8ef-8cc2-404b-b650-d1a9e76d2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///./pizza_v2.db\")\n",
    "from langchain.chains import SQLDatabaseChain, SQLDatabaseSequentialChain\n",
    "seq_chain = SQLDatabaseSequentialChain.from_llm(llm, db, verbose=True)\n",
    "\n",
    "# possibly customize SQLDatabaseChain to handle empty table list from SQLDatabaseSequentialChain\n",
    "# then pass SQLDatabaseChain into the sequential chain\n",
    "\n",
    "#seq_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f4055cd-fbc1-4c88-8ae5-743eb5eeab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = \"menu search\",\n",
    "        func=seq_chain.run,\n",
    "        description=\"\"\"useful for when you need to answer questions about menu items the user wants to order.\n",
    "        Search your chat history before deciding you need to use this.\"\"\"\n",
    "    ),\n",
    "\n",
    "        Tool(\n",
    "        name=\"Order summary\",\n",
    "        func=lambda x: \"Summarize the order including total cost\",\n",
    "        description=\"useful for producing a summary of the order\",\n",
    "    ),\n",
    "\n",
    "    # chain that first summarizes and them emails\n",
    "    # maybe need a chain of calls that get email, order summary, then write the email\n",
    "\n",
    "        Tool(\n",
    "        name = \"send email\",\n",
    "        func=send_message,\n",
    "        description=\"\"\"Used when sending the use the email of the order. The input is the output of the order summary tool.\"\"\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a8dcc3d-ab24-4168-b8ee-6c58029b2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom output parser\n",
    "class CustomConvoOutputParser(AgentOutputParser):\n",
    "    def get_format_instructions(self) -> str:\n",
    "        return FORMAT_INSTRUCTIONS\n",
    "\n",
    "    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n",
    "        try:\n",
    "            response = parse_json_markdown(text)\n",
    "            action, action_input = response[\"action\"], response[\"action_input\"]\n",
    "            if action == \"Final Answer\":\n",
    "                return AgentFinish({\"output\": action_input}, text)\n",
    "            else:\n",
    "                return AgentAction(action, action_input, text)\n",
    "        except Exception as e:\n",
    "            # Return instead of throwing an error\n",
    "            return AgentFinish({\"output\": action_input}, text)\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"conversational_chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "092e6c55-80a2-43ce-902e-ec4c99f0bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain = initialize_agent(tools, llm, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "                               verbose=True, memory=memory)\n",
    "agent_chain.agent.output_parser = CustomConvoOutputParser()\n",
    "\n",
    "# try override here\n",
    "#agent_chain.agent.llm_chain.prompt = ChatPromptTemplate goes here, put details in system role if possible\n",
    "\n",
    "# presumably need to define steps so that 1) order taken, 2) summary created, 3) get user email if not already known, \n",
    "# 4) email summary is then sent\n",
    "\n",
    "# access chat memory with agent_chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da3aec-ceee-4e72-8881-bf5977a5d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.memory.chat_memory.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64844ec7-5f7d-4aff-bf3e-abbe60323f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent_chain.agent.output_parser??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f73e656c-d044-4119-bae5-1a7eb2a26e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Hello Tim! How can I assist you today?\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Tim! How can I assist you today?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"hi, i am Tim and my email is t@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38daeb3d-04a1-4ae3-952a-ba183c3cbaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789fb550-6bdb-419f-b690-94f3d55cbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"what is my name and email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef0bd1-80fd-4648-a754-64ca43fe5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run('I would like to order a large pizza and bottled water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f756c-848f-4a42-ba58-cf149db55fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run('What sizes of bottled water do you have?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e995348-6e37-4534-a447-0057615e627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent_chain.run('I will take the bottled water.  What is you most popular pizza?')\n",
    "agent_chain.run('Add the large bottled water to my order.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c36bd-8036-4a17-ac07-8ea708097622",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run('Add the bottled water to my order.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0828971-66ee-4ad9-a438-186092bd9cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"menu search\",\n",
      "    \"action_input\": \"large pepperoni pizza with sausage and extra cheese\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timw/venv/llm/lib/python3.11/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table names to use:\n",
      "\u001b[33;1m\u001b[1;3m['pizzas', 'toppings']\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "large pepperoni pizza with sausage and extra cheese\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT pizzas.Item, pizzas.Price_Large, toppings.Price\n",
      "FROM pizzas, toppings\n",
      "WHERE pizzas.Item = 'Pepperoni pizza' AND toppings.Item IN ('Sausage', 'Extra cheese')\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('Pepperoni pizza', '12.95', '2.00'), ('Pepperoni pizza', '12.95', '3.00')]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThe price of a large pepperoni pizza with sausage and extra cheese is $17.95 (12.95 + 2.00 + 3.00).\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe price of a large pepperoni pizza with sausage and extra cheese is $17.95 (12.95 + 2.00 + 3.00).\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The price of a large pepperoni pizza with sausage and extra cheese is $17.95 (12.95 + 2.00 + 3.00).\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The price of a large pepperoni pizza with sausage and extra cheese is $17.95 (12.95 + 2.00 + 3.00).'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"\"\"I would like to order the large pepperoni \\\n",
    "pizza. Please include both sausage and extra cheese as additional \\\n",
    "toppings.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c26f57f6-566a-4dee-9a29-3a663115e4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Order summary\",\n",
      "    \"action_input\": \"t@gmail.com\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mSummarize the order including total cost\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Your order is a large pepperoni pizza with sausage and extra cheese, and the total cost is $17.95.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your order is a large pepperoni pizza with sausage and extra cheese, and the total cost is $17.95.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"Please repeat my order to make sure it is right.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64b1d0-ea3a-44b1-b6d9-b68f7e43dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"how many kinds of fish do you sell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d51898be-b3c9-4369-8a78-51c21a185f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"send email\",\n",
      "    \"action_input\": \"Here is your order summary:\\n\\nLarge Pepperoni Pizza with Sausage and Extra Cheese\\nTotal Cost: $17.95\\n\\nThank you for your order!\"\n",
      "}\n",
      "```\u001b[0mContent-Type: multipart/mixed; boundary=\"===============7057915733348356565==\"\n",
      "MIME-Version: 1.0\n",
      "From: OrderBotPizza.com\n",
      "To: user@user.com\n",
      "Subject: Your OrderBot Pizza Order\n",
      "\n",
      "--===============7057915733348356565==\n",
      "Content-Type: text/html; charset=\"us-ascii\"\n",
      "MIME-Version: 1.0\n",
      "Content-Transfer-Encoding: 7bit\n",
      "\n",
      "Here is your order summary:\n",
      "\n",
      "Large Pepperoni Pizza with Sausage and Extra Cheese\n",
      "Total Cost: $17.95\n",
      "\n",
      "Thank you for your order!\n",
      "--===============7057915733348356565==--\n",
      "\n",
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m(<email.mime.multipart.MIMEMultipart object at 0x7f0c796a2e10>, 'mail sent successfully')\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Your order summary has been sent to your email. Thank you for your order!\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your order summary has been sent to your email. Thank you for your order!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"that is it. please email me my receipt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0fe86d-fdb4-4c60-b6e8-45249469ab65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
