In the previous post http://loveofdatascience.blogspot.com/2023/06/an-introduction-to-prompt-engineering.html about prompt engineering for large language models (LLMs), I demonstrated that ChatGPT could navigate word math problems if prompted suitably. In this post, I explore ChatGPT's ability to reason about tabular data, including relational database tables. The source code and raw materials used to build this article are available here https://github.com/tweinzirl/chatGPT_practice/tree/master/blog2 .

# Pizza Time! (No Mushrooms Please)

The DeepLearning.AI short course on prompt engineering https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction culminates with the demo of a pizza OrderBot. The bot is able to answer questions about the menu, gather the order, and summarize the whole thing at the end, complete with the correct total price. The menu in this example is represented in plain text within a system role message (Figure 1).

[fig1.png - chatbot prompt and pizza menu]

Figure 2 shows an example of a complete order executed by the bot.

[fig2.png - sample order]

One well-known problem with LLMs, however, is their tendency to hallucinate https://machinelearningmastery.com/a-gentle-introduction-to-hallucinations-in-large-language-models. Asking about details not provided in the prompt causes the model make up details based on its original training. This can be dangerous in production applications because even LLM inaccurate responses can sound reasonable. Figure 3 shows examples of hallucinations about details not provided in the pizza menu. 

[fig3.png - example of water hallucination]

The errors in these specific examples are fixable by adding more details (diameters of pizzas, sizes of drinks) to the menu text in the prompt. Fool-proofing the menu would be an iterative process that could potentially cause regressions as menu complexity increases.


# Querying structured data

In the above example, ChatGPT was able to reason about the menu surprisingly well. Here, I explore if hallucinations are reduced when the menu is structured in SQL tables instead of unstructured text. I hypothesize that well-chosen table and column names would be used as metadata to help the LLM understand how and whether to answer a given question.

To set up the database, dataframes were made for each each category of item (pizza, topping, side item, drink). They were first prototyped as pandas dataframes and then loaded into a SQLite https://www.sqlite.org/index.html database with SQLAlchemy https://www.sqlalchemy.org/. The table schemas consist of the item name, price, and item description. Figure 4 shows the full content of the tables.

[Figure 4 - Pizza menu]

ChatGPT was connected to the database via LangChain https://python.langchain.com/docs/get_started/introduction.html , an exciting new open source framework for incorporating LLMs into applications. The project that provides modular components for a) connecting LLMs to external data sources and b) accomplishing higher level tasks like as Q&A sessions. The components can be chained together to create arbitrarily complex applications. The short, and currently free, langchain course https://learn.deeplearning.ai/langchain/lesson/1/introduction from deeplearning.ai https://www.deeplearning.ai provides an accessible introduction to the package.

LangChain provides a SQLDatabaseChain component https://python.langchain.com/docs/modules/chains/popular/sqlite that is pre-configured to query data in any database compatible with SQLAlchemy. The tool implements established best practices https://arxiv.org/abs/2204.00498 for prompting an LLM to write SQL queries, although futher customization of the prompt is possible. The minimal steps for setting up the SQLDatabaseChain include connecting to the database and initializing an LLM https://python.langchain.com/docs/modules/model_io/models/ (Figure 5).  After experimenting with my own prompt, I adopted the default prompt.

[fig5 - set up db chain and view custom prompt]

I expect the SQL chain to perform at least as well as the previous implementation, so I start by presenting the three inputs that caused hallucinations in Figure 3. Impressively, the SQL chain answers all the questions correctly and without hallucinating false details. Figure 6 shows the results. Some of the output remarks (e.g., "The sizes and their corresponding dimensions are not provided in the database.") are not necessarily things that should be shown to end users, and prompting the model to use a different tone would be worthwhile.

[fig6 - three examples of prior hallucinations fixed]

Some comments are in order: [bullet list]


These examples demonstrate the ability of the LLM to examine the data schema and write the SQL needed to efficiently solve the problem. In each case, the SQL chain is following the process specified in the prompt: identify the question, write the SQL query, get the query output, formulate the final answer.

/bullet
In the first example (how many sizes of pizza and how big they are), the LLM inferred from the Price_Large, Price_Medium, and Price_Small fields that there the three pizza sizes are Large, Medium, and Small. It did not confuse the prices as measurements of size (although, see below where this does happen), and it correctly stated that information of dimensions is not available.

In the second example (number and sizes of bottled water), the LLM found only one row and read from the description that the size is 20 ounces. The Price_Medium and Price_Small columns where NULL, but it is not clear this was used in the answer. Asking a related question on the number, size, and cost of Coke returns a detailed and correct answer, which suggests the LLM did not find the answer by accident.

In the third case (Greek salad as a topping), the LLM joined the <it>pizzas</it> and <it>toppings</it> tables together, found no rows where 'Greek salad' was a topping, and concluded it was not possible.

/bullet

As impressive as the above results are, the LLM can fool itself on seemingly simple questions. When asked simply about the diameters of pizza size (which was answered correctly above as part of a longer question), the LLM confuses the price values for pizza dimensions. When asked a second time and reminded that the price values are dollars and not dimensions, it correctly reports that it cannot answer the question.

[fig7 - confusion about pizza diameter]

As a final example, I ask about the size of a small cheese pizza topped with mushroom and sausage. The chain manages to join the <it>pizzas</it> and <it>toppings</it> tables together in a way that returns 0 rows (Figure 8). This is disappointing since the original chatbot with the text menu could answer such a question. Non-invasive ways to fix this text-to-SQL brittleness customizing the prompt instructions https://python.langchain.com/docs/modules/chains/popular/sqlite#customize-prompt instructions and/or including sample rows in the prompt https://python.langchain.com/docs/modules/chains/popular/sqlite#adding-example-rows-from-each-table.

[fig8 - wrong pizza price query]

In this case, I tried out the SQLDatabaseSequentialChain https://python.langchain.com/docs/modules/chains/popular/sqlite#sqldatabasesequentialchain which first examines the schema to decide which tables are relevant and then calls the SQLDatabaseChain for the relevant tables. The result is correct and is shown in Figure 9. The better outcome is not a fluke. The sequential chain consistently outperforms the simpler chain in repeat trials. It might be that the sequential chain is giving the LLM a more detailed examination of the table schemas, so that it is able to write more relevant SQL.

[fig9 - correct pizza price query.]

# Better Ingredients, Better PizzaBot

Using the lessons learned above, I now assemble a custom pizza OrderBot that resolves the shortcomings around hallucinations that were shared above. In addition to working from a database representation of the pizza menu (Figure 4), I would like the bot to be able to send a summary of the order to the user's email. The bot will have to converse with the user in real time and know when to acccess tools for searching the database and sending the summary email.

The langchain Agent interface is able to select which, if any, of the available tools should be called based on the user input. 
Referencing detailed examples (especially this one https://python.langchain.com/docs/modules/agents/how_to/sharedmemory_for_tools) from langchain's documentation, I was able prototype the desired functionality in my own customized agent.

The final solution https://github.com/tweinzirl/chatGPT_practice/blob/master/blog2/pizza_agent_v2.ipynb consists of the following components, which are customized separately before integration:
\bullet
 - A conversational agent (langchain.agents.ConversationalAgent https://python.langchain.com/docs/modules/agents/agent_types/chat_conversation_agent.html) with a custom prompt spelling out its role as an OrderBot.
 - Conversation memory https://python.langchain.com/docs/modules/memory/ buffers (langchain.memory.ConversationBufferMemory, langchain.memory.ReadOnlySharedMemory)
 - SQLDatabaseChain for querying the pizza database (see the above implementation for details)
 - An LLMChain https://python.langchain.com/docs/modules/chains/foundational/llm_chain . This cain is specifically prompted to summarize the order given the conversation history (ReadOnlyShareMemory)
 - A Custom email function: input is a single pipe-delimited string containing order summary and recipient email address
 - An underlying LLM (gpt-3.5-turbo)
\bullet

The separate tools (for database search, order summary, and sending the email) were separately defined.  The order summary tool is just an LLMChain with a custom prompt. Given the chat history (via an instance of ReadOnlySharedMemory), it will summarize the name and price of each item, as well as the total price. The code for the this tool (order_summary) is shown in Figure 10.

[fig10.png - LLM chain for order summary]

The tools setup as a list of langchain.agent.Tool objects. Each Tool object knows its own name (e.g., 'Menu Search'), what function it points to, and has a text description the LLM parses when deciding which tool to call. Figure 11 shows the final configuration of the tools. Note the Order Summary tool additionally has the return_direct=True parameter, which returns the output of the tool directly to the agent (otherwise the LLM would read and rephrase the order summary).

[fig11.png - tool configuration]

The Send Email tool (Figure 12) is the most interesting. I specify in the description that the input is one pipe-delimited string containing the order summary text and the user's email. The send_message function then parses the substrings before it formats the email.

[fig12.png - send_message function]

To make the OrderBot more self-aware about its role in the pizza ordering process, the ConversationalAgent's prompt needs to be edited. This prompt is detailed an includes a prefix, a description of available tools, and a suffix. I use the prefix to explain the OrderBot;s function. The tool list is automatically populated from the existing list of tools. The suffix has placefholders for the chat history, user input, and a scratchpad for the agent to compose a response. Figure 13 shows the code for updating the prompt while Figure 14 shows the fully formatted prompt template.

[fig13 - customize the agent prompt]

[fig14 - final agent prompt template]

As shown in Figure 15, the final agent chain (agent_chain) comes from bringing the components together in the langchain.agents.AgentExecutor.from_agent_and_tools method. Note, custom agent (agent) gets the custom prompt (agent_prompt) by way of an LLMChain. To prevent any parsing errors from causing a problem, the agent_chain.handle_parsing_errors parameter is set to True.

[fig15 - combining all the pieces for the agent]

The pizza OrderBot is finally read to use. The OrderBot turned out to be upbeat, friendly, and addressed me by name. It could answer questions about the menu from the databas exactly as shown above.  Figure 16 shows an example of a correctly handled order.  Figure 17 shows the email summary that was sent.

[fig16.png - conversation summary]

[fig17.png - email order summary]

I am largely satisfied with the prototype OrderBot. I experienced some difficulty with getting the emails to be formatted consistently. Experiments around formatting the order summary as an HTML table did not work. Getting the LLM to use some HTML (e.g., line breaks) would be helpful for summarizing long orders. 

Summary:

In this article, I have examined ChatGPT's ability to query and reason about tabular data. I found some indication that tabular data (a pizza menu) stored as plain text can inspire LLM hallucinations. Splitting the menu into multiple database tables seems to mitigate, but not eliminate, hallucinations. Text-to-SQL capabilities are improving but still show brittleness. Finally, a custom agent OrderBot capable of reading from a database and sending an email was presented. 

Note: This article was produced with langchain 0.0.220 and ChatGPT gpt-3.5-turbo-0301.
