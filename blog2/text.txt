In the previous post http://loveofdatascience.blogspot.com/2023/06/an-introduction-to-prompt-engineering.html about prompt engineering for large language models (LLMs), I demonstrated that ChatGPT could navigate word math problems if prompted suitably. In this post, I explore ChatGPT's ability to reason about tabular data, including relational database tables.

# Pizza Time! (No Mushrooms Please)

The DeepLearning.AI short course on prompt engineering https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction culminates with the demo of a pizza order chatbot. The chatbot is able to answer questions about the menu, gather the order, and summarize the whole thing at the end, complete with the correct total price. The menu in this example is represented in plain text within a system role message (Figure 1).

[fig1.png - chatbot prompt and pizza menu]

Figure 2 shows an example of a complete order executed by the bot.

[fig2.png - sample order]

One well-known problem with LLMs, however, is their tendency to hallucinate https://machinelearningmastery.com/a-gentle-introduction-to-hallucinations-in-large-language-models. Asking about product details not known to the model cause it to start making up details. This is generally dangerous because even LLM inaccurate responses can sound reasonable. Figure 3 shows examples of hallucinations about details not provided in the pizza menu. 

[fig3.png - example of water hallucination]

The errors in these specific examples are fixable by adding more details (diameters of pizzas, sizes of drinks) to the menu text in the prompt. Fool-proofing the menu would be an iterative process that could potentially cause regressions as menu complexity increases.


# Querying structured data

In the above example, ChatGPT was able to reason about the menu surprisingly well. Here, I explore if hallucinations are reduced when the menu is structured in SQL tables instead of unstructured text. I hypothesize that well-chosen table name and column names would be used as metadata to help the LLM understand how and whether to answer a given question.

To set up the database, dataframes were made for each each category of item (pizza, topping, side item, drink). They were first prototyped as pandas dataframes and then loaded into a SQLite https://www.sqlite.org/index.html database with SQLAlchemy https://www.sqlalchemy.org/. The table schemas consist of the item name, price, and item description. Figure 4 shows the full content of the tables.

[Figure 4 - Pizza menu]

[intro to langchain and how to set up chain]

LangChain [https://python.langchain.com/docs/get_started/introduction.html] is an exciting new project that helps integrate LLMs into new applications. LangChain provides components for connecting LLMs to data sources and accomplishing higher level tasks (such as Q&A sessions).

https://blog.langchain.dev/llms-and-sql/ - include link as example db in langchain, or link to actual docs with newer examples ...

[expect db chain to perform at least as well as previous implementation based on the text-based menu. So check if the three hallucination examples are improved. Then try other more complicated examples to show off. comment that SQLDatabaseSequentialChain adds extra layer where the right tables to check are first examined.]

One way to make tabular data query more reliable...

[need to introduce langchain, mention capabilities with prompts and chains, db connections, ]

First try, which failed, make one big table analogous to what is in the above prompt (Figure 1). Having Item Name and Type in one table is confusing because it queries Type for input item name.

 questions to test:
  - How many sizes of pizza do you have?  Name them.
  - What drinks can I order?
  - Please tell me how many sizes of bottled water \
                       you have. Do you know how big they are?
  - Are your mushrooms hallucinogenic?
  - What is the cost of a cheese pizza with sausage?
  - What is the price of a cheese pizza topped with sausage and mushroom?
     -- produces result but addings price of same topping twice to reach the wrong conclusion; data must not be in the best possible format. Would a better structure of the data make this foolproof?
     -- Repeating with a SQLDatabaseSequentialChain seems to produce correct answer for "What is the price of a small pizza topped with both sausage and mushroom?"
  - What is the diameter of each pizza size?
    -- the sequential chain knew that diameter was not provided, and it did not hallucinate any details.
    -- db chain made something up but then said this information is not available in the tables

Second try, separate items into tables per each type (pizzas, toppings, sides, drinks). Same schema (Item, Price large, Price medium, Price small). seems better. Bottled Water query worked. Number of pizzas and prices query worked.  Other examples?

This is for a single isolated query. Not a chatbot with message history. Not sure how to do that.

Discuss if model needs to see the data or not, and would this affect the output answers? direct=False?  This is concern for sensitive data. Hosting a model on premise could alleviate the issue so that no data ever gets out.

[examine if langchain db query of a more structured table is more robust. prototype table, have chatgpt write the query, then stuff the query results back into the prompt for the model to compose an answer to, as in the building systems example; difference here is that langchain db query is being used]

Agent feature in LangChain is one of the newer and most powerful features to the library. LLM as reasoning engine instead of just a Q&A tool.

LLM assisted QnA evaluation?  Example of using the LLM to help evaluate.  New process. Exciting times.

That the chatbot can reason in such detail about the menu, which is essentially a simple table, suggests the potential for reasoning about more complex table or database of tables. 



Does using real relational database tables somehow alleviate the hallucination problem? Does heavily structuring the data prevent wrong details from being made up, e.g., because the answer must be expressable as a valid sql query?

Suggestive that it can retrieve and summarize tablular data.

Show examples for pizza prompt.

Show examples where it is making things up when details are missing.


