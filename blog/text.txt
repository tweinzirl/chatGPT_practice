It has been over 6 months since the public release of ChatGPT in November 2022. The service was an immediate hit. As the most sophisticated example of a large language model (LLM) to date, the Internet wasted no time in interrogating its capabilities (link: https://www.reddit.com/r/ChatGPT/comments/12xk493/what_has_chatgpt_done_recently_that_blew_your_mind/). As LLMs mature, dependence on such AI in daily life could increase dramatically.
While the interactive web app [link: https://chat.openai.com/] is the easiest way for users to leverage ChatGPT, novel future applications will require integration into devices or services, with programmatic access being made available through APIs.

OpenAI provides a ChatGPT API for Python and node.js, and the broader community provides libraries for other languages [link: https://platform.openai.com/docs/libraries]. Apart from the official documentation, another great way to learn is through the short ChatGPT courses (link: https://www.deeplearning.ai/short-courses/) currently on offer for free by DeepLearning.AI. As a new user to the API, the most surprising takeaway from the courses was that basic Python skills combined with the OpenAI API are sufficient to build new, ChatGPT-powered systems.

This article memorializes the key lessons I learned about using OpenAI's ChatGPT API. It is intended to be a reference for myself and a tutorial for new users to the API. The resources from the short courses are available here [https://github.com/tweinzirl/chatGPT_practice/tree/master] and the original examples produced for this article are here [https://github.com/tweinzirl/chatGPT_practice/tree/master/blog].

# Basic setup and authentication

Getting started in Python requires two steps: 1) installing the OpenAI module (pip install openai) and 2) acquiring an API key [https://platform.openai.com/account/api-keys]. In code, the API needs to be aware of the API key. It is not recommended to hardcode the key in the code itslef, and such code should never be submitted to a public repository. A simple alternative is to store the api in a local file called .env and to use the dotenv module [https://github.com/theskumar/python-dotenv] (pip install dotenv) to detect the file and load the key as an environment variable.  Figure 1 provides an example of how this can work:

[fig1.png of authentication]

# Your first API call

Everything is now in place start talking to ChatGPT. The Chat Completion (https://platform.openai.com/docs/api-reference/chat/create) function creates a model response given a chat conversation. The chat conversation can be a single prompt or an entire chat history. In either case, the model parses the text and returns the most likely response. 

Figure 2 shows an example helper function for obtaining the response for a single prompt. This function produces a reponse for exactly one message. Followup calls with different messages will be treated as different conversations.

[fig2.png message completion]

A few comments are in order.
 1) The 'model' argument configures which language model to use. The GPT-3.5 model family can generate natural language and computer code. Of these, gpt-3.5-turbo is recommended as the best performance per cost ($0.002 per 1K tokens, which is approximately 750 words). The full list of models is available here [https://platform.openai.com/docs/models/overview]. 

 5) The 'temperature' argument controls the randomness of the response.  Allowable values are in the range [0, 2] and lower values correspond to less randomness.  Even at temperature 0, however, the model is mostly but not entirely deterministic.

The chatCompletion call returns a particular kind of object (openai.openai_object.OpenAIObject) that contains the desired reponse plus additional meta data.  From the full output ('repsonse'), we want only a small piece (response.choices[0].message["content"]). Figure 3 shows the fullresponse and, at the very bottom, the desired relevant output.

[fig 3 output example]

The input prompt can be 'engineered' to maximize the utility of the single output message ("prompt engineering" [https://en.wikipedia.org/wiki/Prompt_engineering] is an emerging new skill in the application of LLMs). In this case, we can tell ChatGPT to include more fields (year written, ashort summary) and to format the output as a JSON object. If we were interested in using this as a Python object, we could convert with Python's built-in JSON utilities.

[fig 4 updated output]

This example highlights the importance of writing clear and specific instructions, which can include asking for structured output.

# Multi-message chats

The ChatGPT model is stateless. Producing coherent conversations requires that all previous messages in the conversation be uploaded every time (increasing the number of tokens used) for the model for generate the next most likely response. The illusion of continuity is created at the expense of each API call becoming slightly more costly as a conversation unfolds.

In the above get_completion function, the user prompt is formatted into a list ('messages') of dictionaries. Each dictionary encodes one message ('content') and the source ('role'). The 'role' indicates the source of each piece of dialog. It has one of three values: 'user' (the human), 'assistant' (the chatbot), and 'system' (context for the assistant not meant to be visible to the user). A multi-message chat will retain the full history of all messages for each role.

Figure 5 demonstrates to pass a multiple messages to the ChatGPT. In this case, the system role is instructing the assistant that is is to speak like Shakespeare, and that the user cannot override that style.  The user then asks to hear a joke in a different style. The model apologizes that it must stick to the specified original style and then delivers a four-line joke complete with rhyme.

[Fig 5 input]

# Reasoning about math word problems

In this next section, let's explore whether ChatGPT can handle word problems. The answer is "yes, if prompted suitably".

I developed exercises that present options for eating out vs cooking at home. The model is supposed to evaluate each option and decide which is cheaper. In addition to choosing the right option, the model also verbalizes the cheaper option and outputs the amount saved daily and annually.

Figure 6 shows my first attempt at a prompt for the base case (eating out costs $15/meal while eating at home is $5/meal; the user always eats three times a day). ChatGPT gets the right answer (eating at home; annual savings of 365*3*($15 - $5) = $10,950). Note that it is useful in many contexts to inform the model that the user's prompt will be specially marked by triple backtick delimiters (```).

[fig 6 prompt v1]

Asking the same question in a second way reveals a weakness in the prompt.  In Figure 7, I presented the cost of eating at home in units of cents ($0.01), hoping to confuse the system.  The model ends of doing the calculation in units of cents, and the output savings are quoted in cents. While this is not technically wrong, it can be considered incorrect for the purpose of standardizing the output to units of dollars.

[fig7]

Figure 8 shows the second version of the prompt in which the model is told to calculate in dollars and make the decision based on the total number of dollars spent per day. The description for the output also reminds the model that daily and annual savings need to be presented in dollars. This version of the prompt produced the expected output.

[fig8]

After just two iterations, we have something promising, but it was only tested on one example. Prompts are ideally tested in aggregate on a battery of examples. The two prompts were tested on the set of five examples described in Table 1. Example 1 is the base case. Examples 2 and 3 mix dollars and cents. Example 4 mixes total cost per day and the total cost per meal.  Example 5 does the same while mixing dollars and cents too.

[markdown table of examples]

For the model to pass each example, it had to choose the right option (a or b) and calculate the total annual savings in dollars. An answer that chooses the right option while getting the units wrong is only half correct.
The total score for each prompt comes from adding the scores for the invidicual examples. The first promot (v1) scored 40% while the second prompt (v2) scored 100%! Table 2 shows the detailed scoring for each test.

[table of test rests, Test, v1 option vs savings correct, v2 option vs savings correct]

Let's examine in detail waht Prompt V1 got wrong. Half of Example 1 is wrong because the output savings is not in dollars. In Example 2, the letters associated with each choice are flipped, and choice (b) is listed before choice (a). ChatGPT outputs the wrong letter (a) and calculates 0 zero savings. The prompt was apparently confused by the choices not following alphabetical order. All of Example 3 is wrong because the model puts out ... code instead of numbers?  Example 4 is fully correct, and is Example 5 partial credit is awarded because the units are wrong.

[figure 9 of choices out of order]

^^^ make the above a bullet list?

If this prompt were included in an a user-facing app, the tests should be repeated periodically to make sure that there is no regression in performance as the prompt or underlying LLM changes.

{decide if any text below should be saved otherwise remove it}

Introduce a few more best prompting practices:
checking if specific conditions are met by the input, specifiying delimiter characters, and providing examples of the desired output ("few-shot prompting").
Give the model time to think, e.g., by explicitly spelling out required steps and asking the model to check its own work along the way.

Tried to trick system by mixing units of dollars and cents. What convention did it follow: convert dollars to cents?  The final annual savings sometimes came out in cents whereas was expecting dollars. Limitations seen around conversion of cents. Tried explicitly asking for for dollars worked some of the time.

Explain in exquisite detail the rational for picking each test case: confusing units sometimes mix cost per day versus cost per meal.

Conclusion from testing: If limitations are found in what the prompt can do, go back to messages and be sure input currencies are standardized to dollars.

Build test suite that measures success at finding the right answer and the right annual savings.  Sometimes the model could select the right choice but did something wrong in regard to the total savings (e.g., using cents versus dollars).  Assign a total score per each test message, with calculating the right answer and total savings being equally weighted.  

The first prompt (v1) got N examples completely right, M examples half right, and O examples all wrong for a total score of X5.

Repeat for second prompt. The total score was much better (X%). This demonstrates the impact of prompt engineering. Problems were uncovered with the model's ability to consistently convert cents to dollars. This suggests the limitation that input currency amounts be standardized to units of dollars.

# Describe but don't show other capabilities, which most people are familiar with anyway: summarizing, extracting, inferring, transforming/translating.

# more sophisticated data query, tables in text, also langchain sql?  query long text from embedding vector db?

# Conclusion

This article has demonstrated important strategies in designing prompts for ChatGPT LLMs.
[enumerate specific output format, clear instructions in the user and/or system roles,
giving the model time to think by spelling out in detail the steps it should follow.
Prompt development is iterative.
Testing of prompts is best done iteratively with a collection of well-designed examples.
Detailed responses can be graded in terms of more than one criteria, and a composite score comes from adding up the grades for each example. For prompts under active development, the tests should be re-run periodically to prevent regressions in system performance.
]
