It has been over 6 months since the public release of ChatGPT in November 2022. The service was an immediate hit. As the most sophisticated example of a large language model (LLM) to date, the Internet wasted no time in interrogating its capabilities (link: https://www.reddit.com/r/ChatGPT/comments/12xk493/what_has_chatgpt_done_recently_that_blew_your_mind/). As LLMs mature, dependence on such AI in daily life could increase dramatically.
While the interactive web app [link: https://chat.openai.com/] is the easiest way for users to leverage ChatGPT, novel future applications will require integration into devices or services, with programmatic access being made available through APIs.

OpenAI provides a ChatGPT API for Python and node.js, and the broader community provides libraries for other languages [link: https://platform.openai.com/docs/libraries]. Apart from the official documentation, another great way to learn is through the short ChatGPT courses (link: https://www.deeplearning.ai/short-courses/) currently on offer for free by DeepLearning.AI. As a new user to the API, the most surprising takeaway from the courses was that basic Python skills combined with the OpenAI API are sufficient to build new, ChatGPT-powered systems.

This article memorializes the key lessons I learned about using OpenAI's ChatGPT API. It is intended to be a reference for myself and a tutorial for new users to the API. The resources from the short courses are available here [https://github.com/tweinzirl/chatGPT_practice/tree/master] and the original examples produced for this article are here [https://github.com/tweinzirl/chatGPT_practice/tree/master/blog].

# Basic setup and authentication

Getting started in Python requires two steps: 1) installing the OpenAI module (pip install openai) and 2) acquiring an API key [https://platform.openai.com/account/api-keys]. In code, the API needs to be aware of the API key. It is not recommended to hard code the key in the code itself, and such code should never be submitted to a public repository. A simple alternative is to store the API in a local file called .env and to use the dotenv module [https://github.com/theskumar/python-dotenv] (pip install dotenv) to detect the file and load the key as an environment variable.  Figure 1 provides an example of how this can work:

[fig1.png of authentication]

# Your first API call

Everything is now in place to start talking to ChatGPT. The Chat Completion (https://platform.openai.com/docs/api-reference/chat/create) function creates a model response given a chat conversation. The chat conversation can be a single prompt or an entire chat history. In either case, the model parses the text and returns the most likely response. 

Figure 2 shows an example helper function for obtaining the response for a single prompt. This function produces a response for exactly one message. Follow-up calls with different messages will be treated as different conversations.

[fig2.png message completion]

Some comments are in order.
 1) The 'model' argument configures which language model to use. The GPT-3.5 model family can generate natural language and computer code. Of these, gpt-3.5-turbo is recommended as the best performance per cost ($0.002 per 1K tokens [https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them], which is approximately 750 words). The full list of models is available here [https://platform.openai.com/docs/models/overview]. 

 2) The 'temperature' argument controls the randomness of the response.  Allowable values are in the range [0, 2] and lower values correspond to less randomness.  Even at temperature 0, however, the model is mostly but not entirely deterministic.

The chatCompletion call returns a particular kind of object (openai.openai_object.OpenAIObject) that contains the desired response plus additional meta data.  From the full output ('response'), we want only a small piece (response.choices[0].message["content"]). Figure 3 shows the full response and, at the very bottom, the desired relevant output.

[fig 3 output example]

The input prompt can be 'engineered' to maximize the utility of the single output message ("prompt engineering" [https://en.wikipedia.org/wiki/Prompt_engineering] is an emerging new skill in the application of LLMs). For example, we can tell ChatGPT to include more fields (year written, short summary) and to format the output as a JSON object. If we were interested in using this as a Python object, we could convert with Python's JSON utilities [https://docs.python.org/3/library/json.html].

[fig 4 updated output]

This example highlights the importance of writing clear and specific instructions, which can include asking for structured output.

# Multi-message chats

The ChatGPT model is stateless. Producing coherent conversations requires that all previous messages in the conversation be uploaded every time (increasing the number of tokens used) for the model for generate the next most likely response. The illusion of continuity is created at the expense of each API call becoming slightly more costly as a conversation unfolds.

In the above get_completion function, the user prompt is formatted into a list ('messages') of dictionaries. Each dictionary encodes one message ('content') and the source ('role'). The 'role' indicates the source of each piece of dialog. It has one of three values: 'user' (the human), 'assistant' (the chatbot), and 'system' (context for the assistant not meant to be visible to the user). A multi-message chat will retain the full history of all messages for each role.

Figure 5 demonstrates passing multiple messages to the ChatGPT. In this case, the system role is instructing the assistant that is is to speak like Shakespeare, and that the user cannot override that style.  The user then asks to hear a joke in a different style. The model apologizes that it must stick to the specified original style and then delivers a four-line joke complete with rhyme.

[Fig 5 input]

With this in mind, it is surprisingly simple to create a chatbot within a Jupyter notebook. In the example below, I have attempted to recreate the famous Duck season versus Rabbit season debate [https://www.youtube.com/watch?v=17ocaZb-bGg] between Bugs Bunny and Daffy Duck. The assistant is Daffy Duck, and the User is Bugs Bunny. Elmer Fudd is standing by with his rifle. The chat window widget is a panel widget [https://panel.holoviz.org/FAQ.html]. Source code for the chat is here [https://github.com/tweinzirl/chatGPT_practice/blob/master/blog/chatbot_example.ipynb].

[Fig 5b chatbot]

# Reasoning about math word problems

In this next section, let's explore whether ChatGPT can handle word problems. The answer is "yes, if prompted suitably".

I developed exercises that present options for eating out versus cooking at home. The model is supposed to evaluate each option and decide which is cheaper. In addition to choosing the right option, the model also verbalizes the cheaper option and outputs the amount saved daily and annually.

Figure 6 shows my first attempt (V1) at a prompt for the base case (eating out costs $15/meal while eating at home is $5/meal; the user always eats three times a day). ChatGPT gets the right answer (eating at home; annual savings of 365*3*($15 - $5) = $10,950). Note that it is useful in many contexts to inform the model that the user's prompt will be specially marked by delimiters such as triple backticks (```).

[fig 6 prompt v1]

Asking the same question in a second way reveals a weakness in the prompt.  In Figure 7, I presented the cost of eating at home in units of cents ($0.01), hoping to confuse the system.  The model ends of doing the calculation in units of cents, and the output savings are quoted in cents. While this is not technically wrong, it can be considered incorrect since it is atypical to express amounts exceeding $1 in cents.

[fig7]

Figure 8 shows the second version (V2) of the prompt in which the model is told to calculate in dollars and make the decision based on the total number of dollars spent per day. The description for the output also reminds the model that daily and annual savings need to be presented in dollars. This version of the prompt produced the expected output.

[fig8]

After just two iterations, the results were promising. However, prompts are ideally tested on a battery of examples. The two prompts were tested on the set of five examples described in Table 1. Example 1 is the base case. Examples 2 and 3 mix dollars and cents. Example 4 mixes total cost per day and the total cost per meal. Example 5 does the same while mixing dollars and cents too.

[table1]

For the model to pass each example, it had to choose the right option (a or b) and calculate the total annual savings in dollars. An answer that chooses the right option while getting the units wrong is only half correct.
The total score for each prompt comes from adding the scores for the individual examples. The first promote (v1) scored 40% while the second prompt (v2) scored 100%! Table 2 shows the detailed scoring for each test.

[table of test rests, Test, v1 option vs savings correct, v2 option vs savings correct]

Let's examine in detail what Prompt V1 got wrong. 
[bullet list]
Half of Example 1 is wrong because the output savings is not in dollars. In Example 2, the letters associated with each choice are flipped, and choice (b) is listed before choice (a). ChatGPT outputs the wrong letter (a) and calculates 0 zero savings. The prompt was apparently confused by the choices not following alphabetical order. All of Example 3 is wrong because the model outputs a blob of Python code instead of numbers. Example 4 is fully correct, and is Example 5 partial credit is awarded because the units are wrong.

[figure 9 of choices out of order]

How is prompt V2 guiding to model to get the right answer every time? The prompt is is spurring ChatGPT to write it's own robust Python code that gets the right answer every time. At the end of the code blob (Figure 10), the model is producing is constructing a dictionary in the desired output format.

[possible fig 10]

If this prompt were included in an a user-facing app, the tests should be repeated periodically to make sure that there is no regression in performance as the prompt or underlying LLM changes. If prompt V2 begins as further examples were added, the decision to e.g., standardize the currency amounts to dollars might have to be made.

{decide if any text below should be saved otherwise remove it}

Introduce a few more best prompting practices:
checking if specific conditions are met by the input, specifying delimiter characters, and providing examples of the desired output ("few-shot prompting").
Give the model time to think, e.g., by explicitly spelling out required steps and asking the model to check its own work along the way.


# Reference but don't show other capabilities, which most people are familiar with anyway: summarizing, extracting, inferring, transforming/translating.

# Conclusion

This article has demonstrated important strategies in designing prompts for ChatGPT LLMs.
Help tactics for improving prompts include providing clear and specific instructions, using delimiters (e.g., ```) to mark user input, telling the model to work through explicitly defined steps, and asking for structured output.
Tuning applications of LLMs is very different from the process needed for other AI models.
Prompt development is iterative and is best done in a systematic, test-driven way. Test criteria can be explicitly as shown here. It is also possible to have the LLM grade it's own response (not discussed here).
For prompts under active development, tests should be re-run periodically to prevent regressions in system performance.

Hopefully this article helps and inspires you to start building new applications with ChatGPT!
